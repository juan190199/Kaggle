{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df_all = pd.concat([df_train, df_test], sort=True).reset_index(drop=True)\n",
    "\n",
    "df_train.name = 'Training set'\n",
    "df_test.name = 'Test set'\n",
    "df_all.name = 'All sets'\n",
    "\n",
    "dfs = [df_train, df_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_train.info())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_missing(df):\n",
    "    for col in df.columns.tolist():\n",
    "        print('{} column missing values: {}'. format(col, df[col].isnull().sum()))\n",
    "\n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Age ##\n",
    "\n",
    "df_all_corr = df_all.corr().abs().unstack().sort_values(kind='quicksort', ascending=True).reset_index()\n",
    "df_all_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_all_corr[df_all_corr['Feature 1'] == 'Age']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_corr = df_all.corr().abs().unstack().sort_values(kind='quicksort', ascending=True).reset_index()\n",
    "df_all_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_all_corr[df_all_corr['Feature 1'] == 'Pclass']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "for pclass in range(1, 4):\n",
    "    for sex in ['female', 'male']:\n",
    "        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
    "\n",
    "print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n",
    "\n",
    "# Fill missing values in age with the median of sex and pclass groups\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Embarked ##\n",
    "\n",
    "df_all[df_all['Embarked'].isnull()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# After researching, Mrs.Stone embarked from Southampton 'S' with her maid Miss Icard\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Fare ##\n",
    "\n",
    "df_all[df_all['Fare'].isnull()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fare is related to family size ('Parch' and 'SibSp') and 'Pclass' features\n",
    "median_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "# Therefore, the median 'Fare' value of a male with a third class ticket and no family is a logical choice to fill the missing value.\n",
    "df_all['Fare'] = df_all['Fare'].fillna(median_fare)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Cabin ##\n",
    "# The cabin feature has many missing values and it cannot be simply ignored because some cabins might have higher survival rates.\n",
    "\n",
    "# The deck column contains the first letter of the cabin column. 'M' stands for missing value.\n",
    "df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "# The first letter of the cabin values are the decks in which they are located\n",
    "df_all_decks = df_all.groupby(['Deck', 'Pclass']).count().drop(\n",
    "    columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']\n",
    ").rename(columns={'Name': 'Count'}).transpose()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_decks\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_pclass_dist(df):\n",
    "    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M':{}, 'T': {}}\n",
    "\n",
    "    decks = df.columns.levels[0]\n",
    "    for deck in decks:\n",
    "        for pclass in range(1, 4):\n",
    "            try:\n",
    "                count = df[deck][pclass][0]\n",
    "                deck_counts[deck][pclass] = count\n",
    "            except KeyError:\n",
    "                deck_counts[deck][pclass] = 0\n",
    "\n",
    "    df_decks = pd.DataFrame(deck_counts)\n",
    "\n",
    "    # Created a dictionary for every passenger class count in every deck\n",
    "    deck_percentages = {}\n",
    "\n",
    "    for col in df_decks.columns:\n",
    "        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n",
    "\n",
    "    return deck_counts, deck_percentages\n",
    "\n",
    "def display_pclass_dist(percentages):\n",
    "    df_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n",
    "    bar_count = np.arange(len(deck_names))\n",
    "    bar_width = 0.7\n",
    "\n",
    "    pclass_1 = df_percentages[0]\n",
    "    pclass_2 = df_percentages[1]\n",
    "    pclass_3 = df_percentages[2]\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.bar(bar_count, pclass_1, color='#87fbb9', edgecolor='black', width=bar_width, label='Passenger class 1')\n",
    "    plt.bar(bar_count, pclass_2, color='#87c9fb', edgecolor='black', width=bar_width, label='Passenger class 2')\n",
    "    plt.bar(bar_count, pclass_3, color='#f37200', edgecolor='black', width=bar_width, label='Passenger class 3')\n",
    "\n",
    "    plt.xlabel('Deck', size=20, labelpad=30)\n",
    "    plt.ylabel('Passenger class percentage', size=20, labelpad=30)\n",
    "    plt.xticks(bar_count, deck_names)\n",
    "    plt.tick_params(axis='x', labelsize=20)\n",
    "    plt.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 20})\n",
    "    plt.title('Passenger class distribution in decks', size=24, y=1)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_deck_count, all_deck_perc = get_pclass_dist(df_all_decks)\n",
    "display_pclass_dist(all_deck_perc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_deck_perc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-71c36b6fe59f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Deck T has the closest resemblance to deck A, so that passenger will be regrouped with deck A\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mdect_regroup\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdf_all\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Deck'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'T'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mdf_all\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdect_regroup\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'Deck'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'A'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Deck T has the closest resemblance to deck A, so that passenger will be regrouped with deck A\n",
    "dect_regroup = df_all[df_all['Deck'] == 'T'].index\n",
    "df_all.loc[dect_regroup, 'Deck'] = 'A'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all_decks_survived = df_all.groupby(['Deck', 'Survived']).count().drop(\n",
    "    columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']\n",
    ").rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "df_all_decks_survived\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_survived_dist(df):\n",
    "    surv_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M':{}, 'T': {}}\n",
    "\n",
    "    decks = df.columns.levels[0]\n",
    "    for deck in decks:\n",
    "        for survive in range(0, 2):\n",
    "                surv_counts[deck][survive] = df[deck][survive][0]\n",
    "\n",
    "    df_surv = pd.DataFrame(surv_counts)\n",
    "\n",
    "    # Created a dictionary for every passenger class count in every deck\n",
    "    surv_percentages = {}\n",
    "\n",
    "    for col in df_surv.columns:\n",
    "        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]\n",
    "\n",
    "    return surv_counts, surv_percentages\n",
    "\n",
    "def display_survived_dist(percentages):\n",
    "    df_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n",
    "    bar_count = np.arange(len(deck_names))\n",
    "    bar_width = 0.7\n",
    "\n",
    "    not_survived = df_percentages[0]\n",
    "    survived = df_percentages[1]\n",
    "\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.bar(bar_count, not_survived, color='#aa99aa', edgecolor='black', width=bar_width, label='Not survived')\n",
    "    plt.bar(bar_count, survived, color='#33cc33', edgecolor='black', width=bar_width, label='Survived')\n",
    "\n",
    "    plt.xlabel('Deck', size=20, labelpad=30)\n",
    "    plt.ylabel('Survival percentage', size=20, labelpad=30)\n",
    "    plt.xticks(bar_count, deck_names)\n",
    "    plt.tick_params(axis='x', labelsize=20)\n",
    "    plt.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 20})\n",
    "    plt.title('Survival percentage in decks', size=24, y=1)\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_surv_counts, all_surv_perc = get_survived_dist(df_all_decks_survived)\n",
    "display_survived_dist(all_surv_perc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_surv_perc\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Regroup decks A, B, C as ABC, since all of them have only 1st class passengers\n",
    "# Regroup decks D, E as DE, since both of them have similar passenger distribution and same survival rate\n",
    "# Regroup decks F, G as FG, since both of them have similar passenger distribution and same survival rate\n",
    "df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\n",
    "df_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\n",
    "df_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n",
    "\n",
    "df_all['Deck'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.drop(['Cabin'], inplace=True, axis=1)\n",
    "\n",
    "def divide_df(all_data):\n",
    "    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n",
    "\n",
    "df_train, df_test = divide_df(df_all)\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "for df in dfs:\n",
    "    display_missing(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "survived = df_train['Survived'].value_counts()[1]\n",
    "not_survived = df_train['Survived'].value_counts()[0]\n",
    "survived_per = survived / df_train.shape[0] * 100\n",
    "not_survived_per = not_survived / df_train.shape[0] * 100\n",
    "\n",
    "print('{} of {} passengers survived and it is the {:.2f}% of the training set.'.format(survived, df_train.shape[0], survived_per))\n",
    "print('{} of {} passengers did not survive and it is the {:.2f}% of the training set.'.format(not_survived, df_train.shape[0], not_survived_per))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.countplot(df_train['Survived'])\n",
    "\n",
    "plt.xlabel('Survival', size=20, labelpad=15)\n",
    "plt.ylabel('Passenger count', size=20, labelpad=15)\n",
    "plt.xticks((0, 1), ['Not survived ({0:.2f}%)'.format(not_survived_per), 'Survived ({0:.2f}%)'.format(survived_per)])\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.tick_params(axis='y', labelsize=16)\n",
    "\n",
    "plt.title('Training set survival distribution', size=24, y=1.10)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training data\n",
    "df_train_corr = df_train.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()\n",
    "df_train_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation coefficient'}, inplace=True)\n",
    "df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)\n",
    "df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation coefficient'] == 1.0].index)\n",
    "\n",
    "# Test data\n",
    "df_test_corr = df_test.corr().abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()\n",
    "df_test_corr.rename(columns={'level_0': 'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation coefficient'}, inplace=True)\n",
    "df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\n",
    "df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr['Correlation coefficient'] == 1.0].index)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = df_train_corr_nd['Correlation coefficient'] > 0.1\n",
    "df_train_corr_nd[corr]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = df_test_corr_nd['Correlation coefficient'] > 0.1\n",
    "df_test_corr_nd[corr]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(30, 30))\n",
    "\n",
    "sns.heatmap(df_train.drop(['PassengerId'], axis=1).corr(), ax=axs[0], annot=True, square=True, cmap='Blues', annot_kws={'size': 16})\n",
    "sns.heatmap(df_test.drop(['PassengerId'], axis=1).corr(), ax=axs[1], annot=True, square=True, cmap='Blues', annot_kws={'size': 16})\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].tick_params(axis='x', labelsize=16)\n",
    "    axs[i].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "axs[0].set_title('Training set correlations', size=24)\n",
    "axs[1].set_title('Test set correlations', size=24)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cont_features = ['Age', 'Fare']\n",
    "surv = df_train['Survived'] == 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(25, 25))\n",
    "plt.subplots_adjust(right=1.75)\n",
    "\n",
    "for i, feature in enumerate(cont_features):\n",
    "    # Distribution of survival in age and fare features\n",
    "    sns.distplot(df_train[~surv][feature], label='Not survived', hist=True, color='#aa99aa', ax=axs[0][i])\n",
    "    sns.distplot(df_train[surv][feature], label='Survived', hist=True, color='#33cc33', ax=axs[0][i])\n",
    "\n",
    "    # Distribution of age and fare features in the training and test sets\n",
    "    sns.distplot(df_train[feature], label='Training set', hist=False, color='#3fbddf', ax=axs[1][i])\n",
    "    sns.distplot(df_test[feature], label='Test set', hist=False, color='#ffcc00', ax=axs[1][i])\n",
    "\n",
    "    axs[0][i].set_xlabel('')\n",
    "    axs[1][i].set_xlabel('')\n",
    "\n",
    "    for j in range(2):\n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    axs[0][i].legend(loc='upper right', prop={'size': 20})\n",
    "    axs[1][i].legend(loc='upper right', prop={'size': 20})\n",
    "    axs[0][i].set_title('Distribution of survival in {}'.format(feature), size=20, y=1.05)\n",
    "\n",
    "axs[1][0].set_title('Distribution of {} feature'.format('Age'), size=20, y=1.05)\n",
    "axs[1][1].set_title('Distribution of {} feature'.format('Fare'), size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\n",
    "plt.subplots_adjust(right=1.5, top=1.25)\n",
    "\n",
    "for i, feature in enumerate(categorical_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, hue='Survived', data=df_train)\n",
    "\n",
    "    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n",
    "    plt.ylabel('Passenger count', size=20, labelpad=15)\n",
    "    plt.tick_params(axis='x', labelsize=20)\n",
    "    plt.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    plt.legend(['Not survived', 'Survived'], loc='upper center', prop={'size': 18})\n",
    "    plt.title('Count of survival in {} feature'.format(feature), size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test], sort=True).reset_index(drop=True)\n",
    "df_all.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(24, 11))\n",
    "sns.countplot(x='Fare', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Fare', size=18, labelpad=20)\n",
    "plt.ylabel('Passenger count', size=18, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Survival count in {} feature'.format('fare'), size=20, y=1.05)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['Age'] = pd.qcut(df_all['Age'], 10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(24, 11))\n",
    "sns.countplot(x='Age', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Age', size=18, labelpad=20)\n",
    "plt.ylabel('Passenger count', size=18, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=10)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Survival count in {} feature'.format('Age'), size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['FamilySize'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(24, 24), ncols=2, nrows=2)\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "sns.barplot(x=df_all['FamilySize'].value_counts().index, y=df_all['FamilySize'].value_counts().values, ax=axs[0][0])\n",
    "axs[0][0].set_title('Family size feature value counts', size=20, y=1.05)\n",
    "sns.countplot(x='FamilySize', hue='Survived', data=df_all, ax=axs[0][1])\n",
    "axs[0][1].set_title('Survival counts in family size ', size=20, y=1.05)\n",
    "\n",
    "# Family Size with 1 are labeled as 'Alone'\n",
    "# Family Size with 2, 3 and 4 are labeled as 'Small'\n",
    "# Family Size with 5 and 6 are labeled as 'Medium'\n",
    "# Family Size with 7, 8 and 11 are labeled as 'Large'\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "\n",
    "df_all['FamilySizeGrouped'] = df_all['FamilySize'].map(family_map)\n",
    "\n",
    "sns.barplot(x=df_all['FamilySizeGrouped'].value_counts().index, y=df_all['FamilySizeGrouped'].value_counts().values, ax=axs[1][0])\n",
    "axs[1][0].set_title('Family size feature value counts after grouping', size=20, y=1.05)\n",
    "sns.countplot(x='FamilySizeGrouped', hue='Survived', data=df_all, ax=axs[1][1])\n",
    "axs[1][1].set_title('Survival counts in family size after grouping', size=20, y=1.05)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i][1].legend(['Not survived', 'Survived'], loc='upper right', prop={'size': 20})\n",
    "    for j in range(2):\n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "        axs[i][j].set_xlabel('')\n",
    "        axs[i][j].set_ylabel('')\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['TicketFrequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(14, 11))\n",
    "sns.countplot(x='TicketFrequency', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Ticket frequency', size=20, labelpad=20)\n",
    "plt.ylabel('Passenger count', size=20, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of survival in {} feature'.format('Ticket frequency'), size=24, y=1.05)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[0])\n",
    "axs[0].set_title('Title feature value counts', size=24, y=1.05)\n",
    "axs[0].tick_params(axis='x', labelsize=10)\n",
    "\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[1])\n",
    "axs[1].set_title('Title feature value counts after grouping', size=24, y=1.05)\n",
    "axs[1].tick_params(axis='x', labelsize=15)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_surname(data):\n",
    "\n",
    "    families = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        name = data.iloc[i]\n",
    "\n",
    "        if '(' in name:\n",
    "            name_no_bracket = name.split('(')[0]\n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "\n",
    "        family = name_no_bracket.split(',')[0]\n",
    "        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n",
    "\n",
    "        for c in string.punctuation:\n",
    "            family = family.replace(c, '').strip()\n",
    "\n",
    "        families.append(family)\n",
    "\n",
    "    return families\n",
    "\n",
    "# Family feature based on surnames\n",
    "df_all['Family'] = extract_surname(df_all['Name'])\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List of families and tickets that are occurring in both training and test set\n",
    "# List of family names (non_unique_families), that are occurring in both training and test set is created.\n",
    "non_unique_families = [x for x in df_train['Family'].unique() if x in df_test['Family'].unique()]\n",
    "non_unique_tickets = [x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()]\n",
    "\n",
    "df_family_survival_rate = df_train.groupby('Family')['Survived', 'Family','FamilySize'].median()\n",
    "df_ticket_survival_rate = df_train.groupby('Ticket')['Survived', 'Ticket','TicketFrequency'].median()\n",
    "\n",
    "family_rates = {}\n",
    "ticket_rates = {}\n",
    "\n",
    "# Checked if a family exists in both training and test set, and has members more than 1\n",
    "for i in range(len(df_family_survival_rate)):\n",
    "    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n",
    "        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n",
    "\n",
    "# Checked if a ticket exists in both training and test set, and has members more than 1\n",
    "for i in range(len(df_ticket_survival_rate)):\n",
    "    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n",
    "        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Family_Survival_Rate is calculated from families in training set since there is no Survived feature in test set.\n",
    "# The survival rate is calculated for families with more than 1 members in that list, and stored in Family_Survival_Rate feature.\n",
    "# An extra binary feature Family_Survival_Rate_NA is created for families that are unique to the test set.\n",
    "# This extra feature is also necessary because there is no way to calculate those families' survival rate and implies that family survival rate is not applicable to those passengers because there is no way to retrieve their survival rate.\n",
    "\n",
    "mean_survival_rate = np.mean(df_train['Survived'])\n",
    "\n",
    "train_family_survival_rate = []\n",
    "train_family_survival_rate_NA = []\n",
    "test_family_survival_rate = []\n",
    "test_family_survival_rate_NA = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['Family'][i] in family_rates:\n",
    "        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n",
    "        train_family_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        train_family_survival_rate.append(mean_survival_rate)\n",
    "        train_family_survival_rate_NA.append(0)\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Family'].iloc[i] in family_rates:\n",
    "        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n",
    "        test_family_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        test_family_survival_rate.append(mean_survival_rate)\n",
    "        test_family_survival_rate_NA.append(0)\n",
    "\n",
    "df_train['FamilySurvivalRate'] = train_family_survival_rate\n",
    "df_train['FamilySurvivalRateNA'] = train_family_survival_rate_NA\n",
    "df_test['FamilySurvivalRate'] = test_family_survival_rate\n",
    "df_test['FamilySurvivalRateNA'] = test_family_survival_rate_NA\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Ticket_Survival_Rate and Ticket_Survival_Rate_NA features are also created with the same method.\n",
    "train_ticket_survival_rate = []\n",
    "train_ticket_survival_rate_NA = []\n",
    "test_ticket_survival_rate = []\n",
    "test_ticket_survival_rate_NA = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['Ticket'][i] in ticket_rates:\n",
    "        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n",
    "        train_ticket_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        train_ticket_survival_rate.append(mean_survival_rate)\n",
    "        train_ticket_survival_rate_NA.append(0)\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Ticket'].iloc[i] in ticket_rates:\n",
    "        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n",
    "        test_ticket_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        test_ticket_survival_rate.append(mean_survival_rate)\n",
    "        test_ticket_survival_rate_NA.append(0)\n",
    "\n",
    "df_train['TicketSurvivalRate'] = train_ticket_survival_rate\n",
    "df_train['TicketSurvivalRateNA'] = train_ticket_survival_rate_NA\n",
    "df_test['TicketSurvivalRate'] = test_ticket_survival_rate\n",
    "df_test['TicketSurvivalRateNA'] = test_ticket_survival_rate_NA\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TicketSurvivalRate and FamilySurvivalRate are averaged and become Survival_Rate.\n",
    "# TicketSurvivalRateNA and FamilySurvivalRateNA are also averaged and become Survival_Rate_NA.\n",
    "for df in [df_train, df_test]:\n",
    "    df['SurvivalRate'] = (df['TicketSurvivalRate'] + df['FamilySurvivalRate']) / 2\n",
    "    df['SurvivalRateNA'] = (df['TicketSurvivalRateNA'] + df['FamilySurvivalRateNA']) / 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'FamilySizeGrouped', 'Age', 'Fare']\n",
    "\n",
    "# LabelEncoder basically labels the classes from 0 to n, converting the aforementioned types into numerical type.\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:\n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The categorical features (Pclass, Sex, Deck, Embarked, Title) are converted to one-hot encoded features with OneHotEncoder.\n",
    "categorical_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'FamilySizeGrouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in categorical_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test], sort=True).reset_index(drop=True)\n",
    "drop_cols = ['Deck', 'Embarked', 'Family', 'FamilySize', 'FamilySizeGrouped', 'Survived',\n",
    "             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n",
    "            'TicketSurvivalRate', 'FamilySurvivalRate', 'TicketSurvivalRateNA', 'FamilySurvivalRateNA']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "df_all.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_all.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    criterion='gini',\n",
    "    n_estimators=1100,\n",
    "    max_depth=5,\n",
    "    min_samples_split=4,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='auto',\n",
    "    oob_score=True,\n",
    "    random_state=101,\n",
    "    n_jobs=1,\n",
    "    verbose=1\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 5\n",
    "oob = 0\n",
    "probs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\n",
    "importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=df_all.columns)\n",
    "fprs, tprs, scores = [], [], []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N, random_state=101, shuffle=True)\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print('Fold {}\\n'.format(fold))\n",
    "\n",
    "    model.fit(X_train[trn_idx], y_train[trn_idx])\n",
    "\n",
    "    # Computing Train AUC score\n",
    "    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], model.predict_proba(X_train[trn_idx])[:, 1])\n",
    "    trn_auc_score = auc(trn_fpr, trn_tpr)\n",
    "    # Computing Validation AUC score\n",
    "    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], model.predict_proba(X_train[val_idx])[:, 1])\n",
    "    val_auc_score = auc(val_fpr, val_tpr)\n",
    "\n",
    "    scores.append((trn_auc_score, val_auc_score))\n",
    "    fprs.append(val_fpr)\n",
    "    tprs.append(val_tpr)\n",
    "\n",
    "    # X_test probabilities\n",
    "    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = model.predict_proba(X_test)[:, 0]\n",
    "    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = model.predict_proba(X_test)[:, 1]\n",
    "    importances.iloc[:, fold - 1] = model.feature_importances_\n",
    "\n",
    "    oob += model.oob_score_ / N\n",
    "    print('Fold {} OOB score: {}\\n'.format(fold, model.oob_score_))\n",
    "\n",
    "print('Average OOB score: {}'.format(oob))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importances['MeanImportance'] = importances.mean(axis=1)\n",
    "importances.sort_values(by='MeanImportance', inplace=True, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "sns.barplot(x='MeanImportance', y=importances.index, data=importances)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "plt.title('Random forest classifier mean feature importance between folds', size=15)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_roc_curve(fprs, tprs):\n",
    "\n",
    "    tprs_interp = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "    # Plotting ROC for each fold and computing AUC scores\n",
    "    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n",
    "        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs_interp[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC fold {} (AUC = {:.3f})'.format(i, roc_auc))\n",
    "\n",
    "    # Plotting ROC for random guessing\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random guessing')\n",
    "\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    # Plotting the mean ROC\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n",
    "\n",
    "    # Plotting the standard deviation around the mean ROC Curve\n",
    "    std_tpr = np.std(tprs_interp, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n",
    "\n",
    "    ax.set_xlabel('False positive rate', size=15, labelpad=20)\n",
    "    ax.set_ylabel('True positive rate', size=15, labelpad=20)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "\n",
    "    ax.set_title('ROC curves of folds', size=20, y=1.02)\n",
    "    ax.legend(loc='lower right', prop={'size': 13})\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fprs, tprs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_survived = [col for col in probs.columns if col.endswith('Prob_1')]\n",
    "probs['1'] = probs[class_survived].sum(axis=1) / N\n",
    "probs['0'] = probs.drop(columns=class_survived).sum(axis=1) / N\n",
    "probs['pred'] = 0\n",
    "pos = probs[probs['1'] >= 0.5].index\n",
    "probs.loc[pos, 'pred'] = 1\n",
    "\n",
    "y_pred = probs['pred'].astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df['Survived'] = y_pred.values\n",
    "submission_df.to_csv('output/submission1.csv', header=True, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}